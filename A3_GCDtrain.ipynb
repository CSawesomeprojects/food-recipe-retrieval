{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchwordemb\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running Models and dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/borna/apps/venv/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0013,  0.0015, -0.0013,  ..., -0.0004, -0.0006,  0.0010],\n",
      "        [-0.0237, -0.0711,  0.0030,  ..., -0.0499,  0.0782,  0.0468],\n",
      "        [-0.0555,  0.0136, -0.0149,  ..., -0.0237,  0.1307, -0.0041],\n",
      "        ...,\n",
      "        [-0.0521,  0.1869, -0.2185,  ...,  0.2384, -0.6327, -0.2994],\n",
      "        [ 0.0019, -0.0814,  0.0135,  ...,  0.0355, -0.1582,  0.0095],\n",
      "        [ 0.3283, -0.1053, -0.3926,  ..., -0.1166, -0.2159, -0.1853]])\n",
      "torch.Size([1, 20, 300])\n",
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "%run ./models.ipynb\n",
    "%run ./data_loader.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 5e-4\n",
    "num_hidden = 8\n",
    "dropout_rate = 0.6\n",
    "init_type = 'uniform'\n",
    "lr = 5e-3\n",
    "lr_decay_epoch = 5000\n",
    "use_cude = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming nodes and edges of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(node_lengths):\n",
    "    '''\n",
    "    :param graphs: a list of graphs (each graph is a dictionary)\n",
    "    'e.g. { 'num_nodes': 3,\n",
    "            'edges':{0: [(0,1), (1, 0)]} } edge_type: edges\n",
    "    '\n",
    "    :return: a list of adjacent matrices and hidden mask\n",
    "    '''  \n",
    "         \n",
    "    for node_length in node_lengths:\n",
    "        \n",
    "        edge_type = 0 #edge_type 0 corresponds to edges between the ingredients\n",
    "        nodes = list(range(0,node_length))\n",
    "        \n",
    "        graph_temp = {}\n",
    "        graph_temp['num_nodes'] = node_length\n",
    "        graph_temp['edges'] = {edge_type: [(x,y) for x in nodes for y in nodes]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_matrix(graphs, n_edges = 1):\n",
    "        '''\n",
    "        :param graphs: a list of graphs (each graph is a dictionary)\n",
    "        'e.g. { 'num_nodes': 3,\n",
    "                'edges':{0: [(0,1), (1, 0)]} } edge_type: edges\n",
    "        '\n",
    "        :return: a list of adjacent matrices and hidden mask\n",
    "        '''\n",
    "\n",
    "        num_graphs = len(graphs)\n",
    "        #max_num_nodes = max([G['num_nodes'] for G in graphs])\n",
    "        \n",
    "        # adjacency matrices with max size as max number of nodes across all graphs\n",
    "        batch_adj_matrices = to_var(torch.zeros(n_edges,num_graphs, max_num_nodes, max_num_nodes))\n",
    "        # mask - BS x MaxNodes (to kill hidden states for not existing nodes)\n",
    "        batch_mask = np.ones((n_edges, num_graphs, max_num_nodes, 1), dtype='float32')  # third dim present to apply mask easily :)\n",
    "        for g, graph in enumerate(graphs):\n",
    "            num_nodes = graph['num_nodes']\n",
    "            edges = graph['edges']\n",
    "            for e_type, links in edges.items():\n",
    "                if e_type == 0:\n",
    "                    for src, dst, dist in links:\n",
    "                        batch_adj_matrices[e_type,g, dst, src] = dist\n",
    "                else if e_type == 1:\n",
    "                    for src, dst in links:\n",
    "                        batch_adj_matrices[e_type, g, dst, src] = 1\n",
    "\n",
    "            # set things in mask to 0\n",
    "            batch_mask[:,g, num_nodes:] = 0\n",
    "        return batch_adj_matrices, to_var(torch.from_numpy(batch_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCD train for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCDtrain(train_loader, adj,model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.lr = lr_scheduler(epoch)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (img, instrs, ingrs, category, target) in enumerate(training_generator): \n",
    "        \n",
    "        \n",
    "        _, vec = torchwordemb.load_word2vec_bin('../data/vocab.bin')\n",
    "        ingrs_embs = nn.Embedding(vec.size(0), 300, padding_idx=0)\n",
    "        \n",
    "        visual_emb, recipe_emb = model(ingrs, adj)\n",
    "        \n",
    "        loss_gcdtrain = criterion(visual_emb, recipe_emb, target)\n",
    "        \n",
    "        loss_gcdtrain.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Uniform Initialization\n",
      "| Uniform Initialization\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    batch_size = 1\n",
    "\n",
    "    params = {'batch_size': batch_size, 'shuffle':True, 'pin_memory':True}\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Scale(256), # rescale the image keeping the original aspect ratio\n",
    "                transforms.CenterCrop(256), # we get only the center of that rescaled\n",
    "                transforms.RandomCrop(224), # random crop within the center crop \n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "                ])\n",
    "\n",
    "\n",
    "    training_set = Loader(data_path='../data', partition = 'train', img_path='../data/' , transform=transform)\n",
    "    training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "\n",
    "    model = GCN(\n",
    "            nfeat = 300,\n",
    "            nhid = num_hidden,\n",
    "            dropout = dropout_rate,\n",
    "            init = init_type\n",
    "            )\n",
    " \n",
    "    optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr = lr,\n",
    "            weight_decay = weight_decay,\n",
    "            momentum = 0.9\n",
    "    )\n",
    "    \n",
    "        \n",
    "    if use_cude:\n",
    "        model.cuda()\n",
    "        cosine_crit = nn.CosineEmbeddingLoss(0.1).cuda()\n",
    "    else:\n",
    "        cosine_crit = nn.CosineEmbeddingLoss(0.1)\n",
    "        \n",
    "    criterion = cosine_crit\n",
    "      \n",
    "        \n",
    "    def lr_scheduler(epoch):\n",
    "        return lr * (0.5 ** (epoch / lr_decay_epoch))\n",
    "\n",
    "    epochs = 1\n",
    "# run epochs\n",
    "for epoch in range(epochs):\n",
    "   \n",
    "    # train for one epoch\n",
    "    adj, to_var =build_adj_matrix(model, n_edges = 1)\n",
    "    train(training_generator, adj,model,criterion, optimizer, epoch)\n",
    "\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
