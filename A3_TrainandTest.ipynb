{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import json\n",
    "from Models import LSTM, GCN, RESNET\n",
    "from Loader import Loader\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train Method \n",
    "By getting generated training data, and the lstm and resnet and the model trained with GCD, we train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, lstm,model,learning_rate=0.01):\n",
    "    hx, cx = lstm.initHidden()\n",
    "    optimizer = optim.Adam(lstm.parameters(), learning_rate)\n",
    "    criterion = nn.CosineEmbeddingLoss(0.1).cuda()\n",
    "    \n",
    "    for epoch in range(0, 10):\n",
    "        loss=0\n",
    "        for i, (img, instrs, ingrs, category, target) in enumerate(X):\n",
    "         if i==1:\n",
    "          break \n",
    "        \n",
    "         for j in range(len(img)): #num_iters=6\n",
    "            image_vector=model(torch.Tensor(img[j]).unsqueeze(0))  # Tensor (1,1024)f\n",
    "            # print(\"image_vector\",image_vector)\n",
    "        \n",
    "\n",
    "            tar = Variable(torch.FloatTensor(1))\n",
    "            print(tar)\n",
    "            tar.data[0] = target[j]\n",
    "\n",
    "            for z in range(len(instrs[0])): #num_iters=20\n",
    "                         \n",
    "                # Iterating on lstm units\n",
    "                lstm_input = instrs[0][z].unsqueeze(0).unsqueeze(0)\n",
    "                lstm_output, hx, cx = lstm(lstm_input, hx, cx) ##hx Tensor (1,1,1024)\n",
    "                                \n",
    "\n",
    "            loss += criterion( hx, image_vector.unsqueeze(0),tar[0])\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "         print(\"loss\",loss.data.item()/20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method convert images in jpeg format to 1024 dimension vector using resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(X,model):\n",
    "    vector2image=dict()\n",
    "    vector_images=[]\n",
    "\n",
    "    for i, (img, instrs, ingrs, category, target) in enumerate(X):\n",
    "        if i==1:\n",
    "            break\n",
    "        for j in range(len(img)): #num_iters=6\n",
    "            image=torch.Tensor(img[j]).unsqueeze(0)\n",
    "            vector = model(torch.Tensor(image))  # Tensor (1,1024)\n",
    "            vector2image[vector]= image\n",
    "            vector_images.append(vector)\n",
    "    return vector_images,vector2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method sort all the images and ranked them based on cosine similarity to a given recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank( imgs, instrs, ingrs):\n",
    "    random.seed(opts.seed)\n",
    "    type_embedding = opts.embtype \n",
    "    im_vecs = imgs \n",
    "    instr_vecs = instrs \n",
    "    names = rec_ids\n",
    "\n",
    "    # Sort based on names to always pick same samples for medr\n",
    "    idxs = np.argsort(names)\n",
    "    names = names[idxs]\n",
    "\n",
    "    # Ranker\n",
    "    N = opts.medr\n",
    "    idxs = range(N)\n",
    "\n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    for i in range(10):\n",
    "\n",
    "        ids = random.sample(xrange(0,len(names)), N)\n",
    "        im_sub = im_vecs[ids,:]\n",
    "        instr_sub = instr_vecs[ids,:]\n",
    "        ids_sub = names[ids]\n",
    "\n",
    "        # if params.embedding == 'image':\n",
    "        if type_embedding == 'image':\n",
    "            sims = np.dot(im_sub,instr_sub.T) # for im2recipe\n",
    "        else:\n",
    "            sims = np.dot(instr_sub,im_sub.T) # for recipe2im\n",
    "\n",
    "        med_rank = []\n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "\n",
    "        for ii in idxs:\n",
    "\n",
    "            name = ids_sub[ii]\n",
    "            # get a column of similarities\n",
    "            sim = sims[ii,:]\n",
    "\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)\n",
    "\n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/N\n",
    "\n",
    "        med = np.median(med_rank)\n",
    "        # print \"median\", med\n",
    "\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/10\n",
    "\n",
    "    return np.average(glob_rank), glob_recall, i, sorting[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test method\n",
    "In the test method we compare all of the train images with a query recipe (from test dataset) in order to retrive the most k similar ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train,X_test ,lstm,resnet, gcn, learning_rate=0.01):\n",
    "    hx, cx = lstm.initHidden()\n",
    "\n",
    "    vector_images, vector2image=image2vector(X_train,resnet)\n",
    "    i=-1\n",
    "    predicted_images=[]\n",
    "    for i, (img, instrs, ingrs, category, target) in enumerate(X_test):\n",
    "        if i==1:\n",
    "          break \n",
    "        for j in range(len(img)): #num_iters=6\n",
    "            y=resnet(torch.Tensor(img[j]).unsqueeze(0))\n",
    "            \n",
    "            for z in range(len(instrs[0])): #num_iters=20\n",
    "                         \n",
    "                # Iterating on lstm units\n",
    "                lstm_input = instrs[0][z].unsqueeze(0).unsqueeze(0)\n",
    "                lstm_output, hx, cx = lstm(lstm_input, hx, cx) ##hx Tens\n",
    "            best_cos =torch.Tensor([-1])\n",
    "            y_predict= None\n",
    "            for v in vector_images: # resn\n",
    "                  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "                  output = cos(hx[0], v)\n",
    "\n",
    "                  if output>best_cos:\n",
    "                   best_cos=output\n",
    "                   y_predict=v\n",
    "\n",
    "            predicted_images.append(vector2image[y_predict])\n",
    "            \n",
    "        medR, recall, img_id, recipe_id = rank(img, instrs, ingrs)\n",
    "    return predicted_images, img_id, recipe_id, medR, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running the train method and the output losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train\\9\\8\\6\\5\\9865f3c216.jpg\n",
      "data\\train\\5\\9\\2\\a\\592ae682ff.jpg\n",
      "data\\train\\c\\3\\9\\3\\c393980778.jpg\n",
      "tensor([9.1834e-41])\n",
      "tensor([4.0638e-44])\n",
      "tensor([-137439019008.])\n",
      "tensor([-267362222080.])\n",
      "tensor([19.7502])\n",
      "tensor([9.1834e-41])\n",
      "loss 220.4025634765625\n",
      "data\\train\\6\\3\\8\\5\\638519fbe3.jpg\n",
      "tensor([2.9427e-44])\n",
      "tensor([8.2677e-44])\n",
      "tensor([8.2500])\n",
      "tensor([2.6888e-17])\n",
      "tensor([1.6255e-43])\n",
      "tensor([-267361763328.])\n",
      "loss 135.14261474609376\n",
      "data\\train\\9\\e\\2\\1\\9e21803a96.jpg\n",
      "data\\train\\a\\f\\c\\a\\afca94b507.jpg\n",
      "data\\train\\8\\c\\5\\1\\8c516e2af5.jpg\n",
      "tensor([3.6434e-44])\n",
      "tensor([1.4854e-43])\n",
      "tensor([4.4842e-44])\n",
      "tensor([2.6625e-44])\n",
      "tensor([6.1657e-44])\n",
      "tensor([7.8473e-44])\n",
      "loss 156.5646484375\n",
      "data\\train\\d\\f\\9\\f\\df9f7c586b.jpg\n",
      "data\\train\\2\\3\\2\\9\\2329cc5c00.jpg\n",
      "tensor([7.0065e-45])\n",
      "tensor([4.3440e-44])\n",
      "tensor([7.1466e-44])\n",
      "tensor([1.2892e-43])\n",
      "tensor([1.3873e-43])\n",
      "tensor([2.3822e-43])\n",
      "loss 119.214453125\n",
      "data\\train\\e\\6\\1\\8\\e618320906.jpg\n",
      "data\\train\\2\\0\\4\\a\\204ae70ea5.jpg\n",
      "tensor([2.9427e-44])\n",
      "tensor([9.1834e-41])\n",
      "tensor([2.9427e-44])\n",
      "tensor([1.3452e-43])\n",
      "tensor([1.8217e-44])\n",
      "tensor([4.4842e-44])\n",
      "loss 156.58724365234374\n",
      "data\\train\\3\\e\\2\\b\\3e2b407660.jpg\n",
      "data\\train\\5\\1\\8\\c\\518c36e8b9.jpg\n",
      "tensor([4.3440e-44])\n",
      "tensor([5.1848e-44])\n",
      "tensor([7.4269e-44])\n",
      "tensor([6.7262e-44])\n",
      "tensor([1.9618e-44])\n",
      "tensor([2.8026e-44])\n",
      "loss 126.36458740234374\n",
      "data\\train\\6\\5\\b\\2\\65b2773219.jpg\n",
      "data\\train\\f\\4\\c\\2\\f4c200ee68.jpg\n",
      "data\\train\\2\\5\\3\\8\\253847756b.jpg\n",
      "tensor([4.2039e-45])\n",
      "tensor([1.7516e-43])\n",
      "tensor([1.3935e-26])\n",
      "tensor([3.1389e-43])\n",
      "tensor([1.7236e-43])\n",
      "tensor([9.8091e-45])\n",
      "loss 186.822607421875\n",
      "data\\train\\5\\b\\0\\c\\5b0c583f20.jpg\n",
      "data\\train\\1\\9\\6\\b\\196bad1b4c.jpg\n",
      "data\\train\\d\\1\\c\\2\\d1c2158e95.jpg\n",
      "data\\train\\6\\2\\9\\7\\62974b4b95.jpg\n",
      "tensor([2.8026e-45])\n",
      "tensor([2.5364e-43])\n",
      "tensor([1.4013e-44])\n",
      "tensor([2.1720e-43])\n",
      "tensor([9.1834e-41])\n",
      "tensor([9.1834e-41])\n",
      "loss 217.2773193359375\n",
      "data\\train\\2\\f\\4\\5\\2f4582d794.jpg\n",
      "tensor([1.7516e-43])\n",
      "tensor([2.3121e-43])\n",
      "tensor([5.0447e-44])\n",
      "tensor([1.1210e-43])\n",
      "tensor([9.5288e-44])\n",
      "tensor([6.3058e-44])\n",
      "loss 156.349267578125\n",
      "data\\train\\6\\5\\2\\f\\652f5dcf4f.jpg\n",
      "data\\train\\3\\7\\5\\7\\37571ddba3.jpg\n",
      "data\\train\\0\\8\\8\\9\\0889c06e96.jpg\n",
      "data\\train\\6\\d\\8\\f\\6d8fd10e87.jpg\n",
      "tensor([1.3312e-43])\n",
      "tensor([6.7262e-44])\n",
      "tensor([2.9287e-43])\n",
      "tensor([2.2421e-44])\n",
      "tensor([2.9147e-43])\n",
      "tensor([1.4574e-43])\n",
      "loss 186.7927490234375\n",
      "data\\train\\3\\2\\7\\a\\327ab3d4d4.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 6\n",
    "\n",
    "params = {'batch_size': batch_size, 'shuffle':True, 'pin_memory':True}\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Scale(256), # rescale the image keeping the original aspect ratio\n",
    "            transforms.CenterCrop(256), # we get only the center of that rescaled\n",
    "            transforms.RandomCrop(224), # random crop within the center crop \n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "            ])\n",
    "\n",
    "\n",
    "training_set = Loader(data_path='data', partition = 'train', img_path='data' , transform=transform)\n",
    "test_set = Loader(data_path='data', partition = 'test', img_path='data' , transform=transform)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "test_generator=data.DataLoader(test_set, **params)\n",
    " \n",
    "\n",
    "hidden_size = 1024\n",
    "lstm = LSTM(hidden_size)\n",
    "resnet = RESNET()\n",
    "gcn = RESNET()\n",
    "\n",
    "train(training_generator,gcn,lstm,resnet)\n",
    "#print (\"Train finished!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of  retrieved images  for one test  recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train\\4\\3\\7\\5\\4375b3aa48.jpg\n",
      "data\\test\\2\\2\\1\\c\\221c920d7e.jpg\n",
      "data\\test\\3\\8\\1\\7\\3817236b6e.jpg\n",
      "data\\test\\2\\4\\1\\e\\241e22d085.jpg\n",
      "data\\test\\0\\9\\7\\8\\0978eea9c9.jpg\n",
      "data\\test\\0\\5\\a\\4\\05a40ab9dc.jpg\n",
      "data\\test\\5\\b\\2\\f\\5b2fbf0ed7.jpg\n",
      "data\\test\\2\\3\\4\\9\\23498c3a46.jpg\n",
      "data\\test\\c\\0\\1\\a\\c01a505708.jpg\n",
      "data\\test\\f\\6\\0\\9\\f609d06812.jpg\n",
      "data\\test\\6\\9\\7\\7\\6977c9a0ea.jpg\n",
      "data\\test\\7\\f\\7\\a\\7f7ab00d7f.jpg\n",
      "data\\test\\d\\d\\d\\c\\dddc7f27a5.jpg\n"
     ]
    }
   ],
   "source": [
    "predicted_images, img_ids, top_recipe_ids, medR, recall=test(training_generator,test_generator,lstm,resnet, gcn)\n",
    "print(predicted_images[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredients': [{'text': '6 ounces penne'}, {'text': '2 cups Beechers Flagship Cheese Sauce (recipe follows)'}, {'text': '1 ounce Cheddar, grated (1/4 cup)'}, {'text': '1 ounce Gruyere cheese, grated (1/4 cup)'}, {'text': '1/4 to 1/2 teaspoon chipotle chili powder (see Note)'}, {'text': '1/4 cup (1/2 stick) unsalted butter'}, {'text': '1/3 cup all-purpose flour'}, {'text': '3 cups milk'}, {'text': '14 ounces semihard cheese (page 23), grated (about 3 1/2 cups)'}, {'text': '2 ounces semisoft cheese (page 23), grated (1/2 cup)'}, {'text': '1/2 teaspoon kosher salt'}, {'text': '1/4 to 1/2 teaspoon chipotle chili powder'}, {'text': '1/8 teaspoon garlic powder'}, {'text': '(makes about 4 cups)'}], 'url': 'http://www.epicurious.com/recipes/food/views/-world-s-best-mac-and-cheese-387747', 'partition': 'train', 'title': 'Worlds Best Mac and Cheese', 'id': '000018c8a5', 'instructions': [{'text': 'Preheat the oven to 350 F. Butter or oil an 8-inch baking dish.'}, {'text': 'Cook the penne 2 minutes less than package directions.'}, {'text': '(It will finish cooking in the oven.)'}, {'text': 'Rinse the pasta in cold water and set aside.'}, {'text': 'Combine the cooked pasta and the sauce in a medium bowl and mix carefully but thoroughly.'}, {'text': 'Scrape the pasta into the prepared baking dish.'}, {'text': 'Sprinkle the top with the cheeses and then the chili powder.'}, {'text': 'Bake, uncovered, for 20 minutes.'}, {'text': 'Let the mac and cheese sit for 5 minutes before serving.'}, {'text': 'Melt the butter in a heavy-bottomed saucepan over medium heat and whisk in the flour.'}, {'text': 'Continue whisking and cooking for 2 minutes.'}, {'text': 'Slowly add the milk, whisking constantly.'}, {'text': 'Cook until the sauce thickens, about 10 minutes, stirring frequently.'}, {'text': 'Remove from the heat.'}, {'text': 'Add the cheeses, salt, chili powder, and garlic powder.'}, {'text': 'Stir until the cheese is melted and all ingredients are incorporated, about 3 minutes.'}, {'text': 'Use immediately, or refrigerate for up to 3 days.'}, {'text': 'This sauce reheats nicely on the stove in a saucepan over low heat.'}, {'text': 'Stir frequently so the sauce doesnt scorch.'}, {'text': 'This recipe can be assembled before baking and frozen for up to 3 monthsjust be sure to use a freezer-to-oven pan and increase the baking time to 50 minutes.'}, {'text': 'One-half teaspoon of chipotle chili powder makes a spicy mac, so make sure your family and friends can handle it!'}, {'text': 'The proportion of pasta to cheese sauce is crucial to the success of the dish.'}, {'text': 'It will look like a lot of sauce for the pasta, but some of the liquid will be absorbed.'}]}\n",
      "{'ingredients': [{'text': '1 c. elbow macaroni'}, {'text': '1 c. cubed American cheese (4 ounce.)'}, {'text': '1/2 c. sliced celery'}, {'text': '1/2 c. minced green pepper'}, {'text': '3 tbsp. minced pimento'}, {'text': '1/2 c. mayonnaise or possibly salad dressing'}, {'text': '1 tbsp. vinegar'}, {'text': '3/4 teaspoon salt'}, {'text': '1/2 teaspoon dry dill weed'}], 'url': 'http://cookeatshare.com/recipes/dilly-macaroni-salad-49166', 'partition': 'train', 'title': 'Dilly Macaroni Salad Recipe', 'id': '000033e39b', 'instructions': [{'text': 'Cook macaroni according to package directions; drain well.'}, {'text': 'Cold.'}, {'text': 'Combine macaroni, cheese cubes, celery, green pepper and pimento.'}, {'text': 'Blend together mayonnaise or possibly salad dressing, vinegar, salt and dill weed; add in to macaroni mix.'}, {'text': 'Toss lightly.'}, {'text': 'Cover and refrigeratewell.'}, {'text': 'Serve salad in lettuce lined bowl if you like.'}, {'text': 'Makes 6 servings.'}]}\n",
      "{'ingredients': [{'text': '8 tomatoes, quartered'}, {'text': 'Kosher salt'}, {'text': '1 red onion, cut into small dice'}, {'text': '1 green bell pepper, cut into small dice'}, {'text': '1 red bell pepper, cut into small dice'}, {'text': '1 yellow bell pepper, cut into small dice'}, {'text': '1/2 cucumber, cut into small dice'}, {'text': 'Extra-virgin olive oil, for drizzling'}, {'text': '3 leaves fresh basil, finely chopped'}], 'url': 'http://www.foodnetwork.com/recipes/gazpacho1.html', 'partition': 'train', 'title': 'Gazpacho', 'id': '000035f7ed', 'instructions': [{'text': 'Add the tomatoes to a food processor with a pinch of salt and puree until smooth.'}, {'text': 'Combine the onions, bell peppers and cucumbers with the tomato puree in a large bowl.'}, {'text': 'Chill at least 1 hour.'}, {'text': 'Drizzle with olive oil, garnish with chopped basil and serve.'}]}\n",
      "{'ingredients': [{'text': '2 12 cups milk'}, {'text': '1 12 cups water'}, {'text': '14 cup butter'}, {'text': 'mashed potatoes, 1 box, homestyle'}, {'text': '1 (8 ounce) can whole kernel corn (drained)'}, {'text': '1 cup cheddar cheese'}, {'text': '1 cup French-fried onions'}], 'url': 'http://www.food.com/recipe/crunchy-onion-potato-bake-479149', 'partition': 'test', 'title': 'Crunchy Onion Potato Bake', 'id': '00003a70b1', 'instructions': [{'text': 'Preheat oven to 350 degrees Fahrenheit.'}, {'text': 'Spray pan with non stick cooking spray.'}, {'text': 'Heat milk, water and butter to boiling; stir in contents of both pouches of potatoes; let stand one minute.'}, {'text': 'Stir in corn.'}, {'text': 'Spoon half the potato mixture in pan.'}, {'text': 'Sprinkle half each of cheese and onions; top with remaining potatoes.'}, {'text': 'Sprinkle with remaining cheese and onions.'}, {'text': 'Bake 10 to 15 minutes until cheese is melted.'}, {'text': 'Enjoy !'}]}\n",
      "{'ingredients': [{'text': '1 (3 ounce) package watermelon gelatin'}, {'text': '14 cup boiling water'}, {'text': '1 (12 ounce) package Cool Whip, thawed'}, {'text': '2 cups cubed seedless watermelon'}, {'text': '1 graham cracker crust'}], 'url': 'http://www.food.com/recipe/cool-n-easy-creamy-watermelon-pie-66340', 'partition': 'train', 'title': \"Cool 'n Easy Creamy Watermelon Pie\", 'id': '00004320bb', 'instructions': [{'text': 'Dissolve Jello in boiling water.'}, {'text': 'Allow to cool to room temp.'}, {'text': 'Whisk in Cool Whip.'}, {'text': 'Fold in watermelon.'}, {'text': 'Spoon into crust.'}, {'text': 'Chill for 2-3 hours or overnight.'}, {'text': 'Yum!'}]}\n",
      "{'ingredients': [{'text': '12 cup shredded coconut'}, {'text': '1 lb lean ground beef'}, {'text': '1 -2 tablespoon minced fresh garlic (or to taste)'}, {'text': 'salt and black pepper'}, {'text': '1 tablespoon lemon juice'}, {'text': '1 tablespoon soy sauce'}, {'text': '2 tablespoons cornstarch'}, {'text': '1 (8 ounce) can pineapple chunks, drained, reserving the liquid'}, {'text': '1 (16 ounce) can mandarin oranges, drained, reserving the liquid'}, {'text': '12 cup cashew nuts'}], 'url': 'http://www.food.com/recipe/easy-tropical-beef-skillet-75863', 'partition': 'train', 'title': 'Easy Tropical Beef Skillet', 'id': '0000631d90', 'instructions': [{'text': 'In a large skillet, toast the coconut over medium heat, until golden and crisp; set aside.'}, {'text': 'Brown ground beef and garlic in the same skillet; drain well.'}, {'text': 'Add salt, pepper lemon juice and soy sauce.'}, {'text': 'In a small bowl combine the cornstarch with reserved pineapple and mandarin orange liquids; stir well until smooth then add to ground beef and cook over medium heat for 5 mins, stirring constantly, until mixture is thickened.'}, {'text': 'Stir in the pineapple and mandarin oranges; cook 2-3 mins, or until thoroughly heated.'}, {'text': 'Serve over noodles or rice, and sprinkle with more toasted coconut and cashew nuts.'}]}\n",
      "{'ingredients': [{'text': '2 Chicken thighs'}, {'text': '2 tsp Kombu tea'}, {'text': '1 White pepper'}], 'url': 'https://cookpad.com/us/recipes/150100-kombu-tea-grilled-chicken-thigh', 'partition': 'train', 'title': 'Kombu Tea Grilled Chicken Thigh', 'id': '000075604a', 'instructions': [{'text': 'Pierce the skin of the chicken with a fork or knife.'}, {'text': 'Sprinkle with kombu tea evenly on both sides of the chicken, about 1 teaspoon per chicken thigh.'}, {'text': 'Brown the skin side of the chicken first over high heat until golden brown.'}, {'text': 'Sprinkle some pepper on the meat just before flipping over.'}, {'text': 'Then brown the other side until golden brown.'}]}\n",
      "{'ingredients': [{'text': '6 -8 cups fresh rhubarb, or'}, {'text': '6 -8 cups frozen rhubarb, thawed'}, {'text': '1 12 cups granulated sugar'}, {'text': '6 ounces strawberry Jell-O gelatin dessert'}, {'text': '1 white cake mix (2 layer size)'}, {'text': '1 12 cups water'}, {'text': '12 cup butter or 12 cup margarine, melted'}], 'url': 'http://www.food.com/recipe/strawberry-rhubarb-dump-cake-408694', 'partition': 'train', 'title': 'Strawberry Rhubarb Dump Cake', 'id': '00007bfd16', 'instructions': [{'text': 'Put ingredients in a buttered 9 x 12 x 2-inch pan in even layers in the order that they are given - DO NOT MIX.'}, {'text': 'Bake in a 350 oven for 1 hour.'}]}\n",
      "{'ingredients': [{'text': '8 ounces, weight Light Fat Free Vanilla Yogurt (I Used Activia)'}, {'text': '1 cup Fresh Sliced Strawberries'}, {'text': '1/4 cups Low-fat Granola'}], 'url': 'http://tastykitchen.com/recipes/breakfastbrunch/yogurt-parfaits/', 'partition': 'train', 'title': 'Yogurt Parfaits', 'id': '000095fc1d', 'instructions': [{'text': 'Layer all ingredients in a serving dish.'}]}\n",
      "{'ingredients': [{'text': '2 cups flour'}, {'text': '1 tablespoon cinnamon'}, {'text': '2 teaspoons baking soda'}, {'text': '1 teaspoon salt'}, {'text': '14 teaspoon baking powder'}, {'text': '3 eggs'}, {'text': '2 cups sugar'}, {'text': '1 cup vegetable oil'}, {'text': '1 tablespoon vanilla'}, {'text': '2 cups grated raw zucchini'}, {'text': '1 cup walnuts'}], 'url': 'http://www.food.com/recipe/zucchini-nut-bread-329682', 'partition': 'train', 'title': 'Zucchini Nut Bread', 'id': '0000973574', 'instructions': [{'text': 'Sift dry ingredients.'}, {'text': 'beat eggs untill frothy, add sugar, oil and vanilla.'}, {'text': 'Beat untillthick.'}, {'text': 'Stir in zucchini.'}, {'text': 'blend in sifted dry ingredients.'}, {'text': 'Fold in nuts.'}, {'text': 'pour in greased loaf pan and bake at 350 degrees for 1 1/2 hours.'}]}\n"
     ]
    }
   ],
   "source": [
    "print(top_recipe_ids)\n",
    "layer1 = json.load(open('../data/recipe1M_layers/layer1.json','r'))\n",
    "for i in top_recipe_ids[10]:\n",
    "    print(layer1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The vector of predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finished! 6 tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Test finished!\",len(predicted_images),(predicted_images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Resulted MedR and Recall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medR = 20.7, recall = 0.09\n"
     ]
    }
   ],
   "source": [
    "print(\"medR = {}, recall = {}\".format(medR, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
